## Attention


| Attention                 | Explain                                                |
| ------------------------- | ------------------------------------------------------ |
| SDPA                      | (scaled dot product attention，缩放点积注意力)         |
| MHA                       | (multi-head attention，多头注意力)                     |
| flash_attn/FlashAttention |                                                        |
| FMHA                      | (Fused Multi-Head Attention, 融合多头注意力)           |
| FMHCA                     | (Fused Multi-Head Cross-Attention, 融合多头交叉注意力) |
| MLA                       | (multi-head latent attention，多头潜在注意力)          |





## Hardware

| Hardware | Explain                                      |
| -------- | -------------------------------------------- |
| SRAM     | (static random access memory,静态随机存储器) |
|          |                                              |
|          |                                              |

